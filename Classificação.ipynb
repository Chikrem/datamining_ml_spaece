{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 5: Aplicando as Features Selecionadas em Algoritmos de ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 - Modelos para Problemas de Classificação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1 - Árvores de Decisão (Decision Trees):\n",
    "\n",
    "##### - Descrição: Divide os dados em subconjuntos com base em valores de features, criando uma estrutura de árvore.\n",
    "##### - Aplicabilidade: Capaz de capturar relações não lineares e interações entre features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n",
    "\n",
    "##### 2 - Support Vector Machines (SVM):\n",
    "\n",
    "##### - Descrição: Encontra o hiperplano que maximiza a margem entre as classes.\n",
    "##### - Aplicabilidade: Bom para problemas de alta dimensionalidade e quando as classes são bem separadas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n",
    "\n",
    "##### 3 - K-Nearest Neighbors (KNN):\n",
    "\n",
    "##### - Descrição: Classifica um ponto com base na maioria das classes dos k pontos mais próximos.\n",
    "##### - Aplicabilidade: Simples e eficaz para pequenos conjuntos de dados com relações não lineares.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n",
    "\n",
    "##### 4 - Naive Bayes:\n",
    "\n",
    "##### - Descrição: Baseado no teorema de Bayes, assume independência entre as features.\n",
    "##### -Aplicabilidade: Funciona bem com grandes conjuntos de dados e para problemas de texto (classificação de spam, por exemplo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
